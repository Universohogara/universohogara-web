
'use client'

import { useState, useEffect, useRef } from 'react'
import { motion, AnimatePresence } from 'framer-motion'
import { Mic, MicOff, Volume2, VolumeX, Sparkles, Moon, AlertCircle, CheckCircle } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Alert, AlertDescription } from '@/components/ui/alert'
import { Progress } from '@/components/ui/progress'
import { toast } from 'sonner'


interface ImprovedVoiceChatProps {
  companion: {
    id: string
    type: string
    name: string
  }
  onVoiceUsage?: (minutesUsed: number, minutesRemaining: number) => void
  onEmotionChange?: (emotion: 'excited' | 'warm' | 'calm' | 'sad' | 'energetic') => void
}

interface VoiceQuotaStatus {
  isPremium: boolean
  minutesUsed: number
  minutesLimit: number
  minutesRemaining: number
  percentageUsed: number
  canUseVoice: boolean
}

interface Message {
  role: 'user' | 'assistant'
  content: string
  emotion?: string
}

export function ImprovedVoiceChat({ companion, onVoiceUsage, onEmotionChange }: ImprovedVoiceChatProps) {
  const [messages, setMessages] = useState<Message[]>([])
  const [isListening, setIsListening] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [isProcessing, setIsProcessing] = useState(false)
  const [quotaStatus, setQuotaStatus] = useState<VoiceQuotaStatus | null>(null)
  const [showMagicMessage, setShowMagicMessage] = useState(false)
  const [useMagicalLanguage, setUseMagicalLanguage] = useState(false)
  const [micPermissionStatus, setMicPermissionStatus] = useState<'unknown' | 'granted' | 'denied' | 'checking'>('unknown')
  
  const recognitionRef = useRef<any>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const currentAudioRef = useRef<AudioBufferSourceNode | null>(null)
  const messagesEndRef = useRef<HTMLDivElement>(null)

  // Auto-scroll
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [messages])

  // Cargar estado de cuota
  useEffect(() => {
    fetchQuotaStatus()
  }, [])

  const fetchQuotaStatus = async () => {
    try {
      const response = await fetch('/api/companion/generate-voice')
      if (response.ok) {
        const data = await response.json()
        setQuotaStatus(data)
        setUseMagicalLanguage(!data.canUseVoice)
      }
    } catch (error) {
      console.error('‚ùå Error obteniendo estado de cuota:', error)
    }
  }

  // Inicializar reconocimiento de voz (SOLO CREAR, NO SOLICITAR PERMISOS)
  useEffect(() => {
    if (typeof window === 'undefined' || !('webkitSpeechRecognition' in window)) {
      console.error('‚ùå Reconocimiento de voz no soportado en este navegador')
      toast.error('Tu navegador no soporta reconocimiento de voz. Usa Chrome o Edge.')
      return
    }

    const SpeechRecognition = (window as any).webkitSpeechRecognition
    recognitionRef.current = new SpeechRecognition()
    recognitionRef.current.continuous = false
    recognitionRef.current.interimResults = true
    recognitionRef.current.lang = 'es-ES'

    recognitionRef.current.onresult = (event: any) => {
      const transcript = Array.from(event.results)
        .map((result: any) => result[0].transcript)
        .join('')
      
      setTranscript(transcript)
      
      // Si es resultado final, procesarlo
      if (event.results[event.results.length - 1].isFinal) {
        handleUserMessage(transcript)
      }
    }

    recognitionRef.current.onerror = (event: any) => {
      console.error('‚ùå Error en reconocimiento de voz:', event.error)
      setIsListening(false)
      
      if (event.error === 'not-allowed' || event.error === 'permission-denied') {
        setMicPermissionStatus('denied')
        toast.error('Permisos de micr√≥fono denegados. Por favor, permite el acceso en la configuraci√≥n de tu navegador.')
      } else if (event.error === 'no-speech') {
        toast.info('No te escuch√©. Intenta hablar m√°s cerca del micr√≥fono.')
      } else if (event.error === 'audio-capture') {
        toast.error('No se detect√≥ ning√∫n micr√≥fono. Conecta un micr√≥fono e intenta de nuevo.')
      } else {
        toast.error(`Error: ${event.error}`)
      }
    }

    recognitionRef.current.onend = () => {
      console.log('üé§ Reconocimiento de voz terminado')
      setIsListening(false)
    }

    return () => {
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop()
        } catch (e) {
          // Ya estaba detenido
        }
      }
    }
  }, [])

  const checkMicrophonePermissions = async (): Promise<boolean> => {
    try {
      setMicPermissionStatus('checking')
      
      // Verificar si hay dispositivos de audio
      const devices = await navigator.mediaDevices.enumerateDevices()
      const audioInputs = devices.filter(device => device.kind === 'audioinput')
      
      if (audioInputs.length === 0) {
        toast.error('No se encontr√≥ ning√∫n micr√≥fono conectado. Por favor conecta un micr√≥fono.')
        setMicPermissionStatus('denied')
        return false
      }

      console.log(`üé§ ${audioInputs.length} micr√≥fono(s) encontrado(s)`)
      
      // Solicitar permiso de micr√≥fono
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      
      // Detener el stream inmediatamente (solo necesit√°bamos verificar permisos)
      stream.getTracks().forEach(track => track.stop())
      
      console.log('‚úÖ Permisos de micr√≥fono concedidos')
      setMicPermissionStatus('granted')
      toast.success('Micr√≥fono listo. Ahora puedes hablar.', { duration: 2000 })
      return true
      
    } catch (error: any) {
      console.error('‚ùå Error al verificar permisos de micr√≥fono:', error)
      setMicPermissionStatus('denied')
      
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        toast.error('Permisos de micr√≥fono denegados. Ve a la configuraci√≥n de tu navegador para permitir el acceso.')
      } else if (error.name === 'NotFoundError') {
        toast.error('No se encontr√≥ ning√∫n micr√≥fono conectado.')
      } else {
        toast.error('No se pudo acceder al micr√≥fono. Verifica que est√© conectado y permitido.')
      }
      
      return false
    }
  }

  const toggleListening = async () => {
    if (!recognitionRef.current) {
      toast.error('Reconocimiento de voz no disponible')
      return
    }

    if (isListening) {
      // Detener escucha
      try {
        recognitionRef.current.stop()
        setIsListening(false)
        setTranscript('')
      } catch (e) {
        console.error('Error deteniendo reconocimiento:', e)
      }
    } else {
      // Verificar permisos primero
      const hasPermission = await checkMicrophonePermissions()
      
      if (!hasPermission) {
        return
      }

      // Iniciar reconocimiento
      try {
        recognitionRef.current.start()
        setIsListening(true)
        setTranscript('')
      } catch (error) {
        console.error('‚ùå Error iniciando reconocimiento:', error)
        toast.error('No se pudo iniciar el reconocimiento de voz')
        setIsListening(false)
      }
    }
  }

  const handleUserMessage = async (text: string) => {
    if (!text.trim() || isProcessing) return

    const userMessage: Message = {
      role: 'user',
      content: text
    }

    setMessages(prev => [...prev, userMessage])
    setIsProcessing(true)
    setTranscript('')

    try {
      // 1. Enviar mensaje al chat para obtener respuesta
      const chatResponse = await fetch('/api/companion/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          companionId: companion.id,
          message: text
        })
      })

      if (!chatResponse.ok) {
        throw new Error('Error obteniendo respuesta del companion')
      }

      const chatData = await chatResponse.json()
      const responseText = chatData.response || 'No pude procesar tu mensaje'

      // Detectar emoci√≥n del texto para animaciones
      const emotion = detectEmotion(responseText)
      
      const assistantMessage: Message = {
        role: 'assistant',
        content: responseText,
        emotion
      }

      setMessages(prev => [...prev, assistantMessage])

      // Notificar cambio de emoci√≥n para animaciones
      if (onEmotionChange) {
        onEmotionChange(emotion)
      }

      // 2. Generar y reproducir voz (sin emojis)
      await generateAndPlayVoice(responseText, emotion)

      // 3. Refrescar estado de cuota
      await fetchQuotaStatus()

    } catch (error) {
      console.error('‚ùå Error procesando mensaje:', error)
      toast.error('Hubo un error procesando tu mensaje')
      
      setMessages(prev => [...prev, {
        role: 'assistant',
        content: 'Lo siento, hubo un error procesando tu mensaje. Por favor intenta de nuevo.'
      }])
    } finally {
      setIsProcessing(false)
    }
  }

  const generateAndPlayVoice = async (text: string, emotion?: string) => {
    try {
      // Limpiar texto de emojis y s√≠mbolos
      const cleanText = cleanTextForSpeech(text)
      
      if (!cleanText.trim()) {
        console.warn('‚ö†Ô∏è Texto vac√≠o despu√©s de limpiar, omitiendo TTS')
        return
      }

      const response = await fetch('/api/companion/generate-voice', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: cleanText, // ‚úÖ Texto limpio sin emojis
          companionType: companion.type,
          emotion // Pasar emoci√≥n detectada
        })
      })

      if (!response.ok) {
        throw new Error('Error generando voz')
      }

      const data = await response.json()

      // Si se debe usar idioma m√°gico
      if (data.useMagicalLanguage) {
        setUseMagicalLanguage(true)
        
        if (data.magicDepletedMessage) {
          setShowMagicMessage(true)
          toast.info(data.magicDepletedMessage, {
            duration: 5000,
            icon: 'üåô'
          })
          setTimeout(() => setShowMagicMessage(false), 5000)
        }

        // Mostrar mensaje en idioma m√°gico en la UI
        toast(data.message, {
          duration: 3000,
          icon: '‚ú®'
        })
        return
      }

      // Reproducir audio de Eleven Labs
      if (data.audioBase64) {
        await playAudioFromBase64(data.audioBase64)
        
        // Actualizar estado de uso
        if (onVoiceUsage) {
          onVoiceUsage(data.minutesUsed, data.minutesRemaining)
        }

        setQuotaStatus(prev => prev ? {
          ...prev,
          minutesUsed: data.minutesUsed,
          minutesRemaining: data.minutesRemaining,
          percentageUsed: Math.round((data.minutesUsed / data.minutesLimit) * 100),
          canUseVoice: data.minutesRemaining > 0
        } : null)
      }

    } catch (error) {
      console.error('‚ùå Error generando/reproduciendo voz:', error)
      toast.error('Error al reproducir la voz')
    }
  }

  const playAudioFromBase64 = async (audioBase64: string) => {
    try {
      setIsSpeaking(true)

      // Inicializar AudioContext si no existe
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext()
      }

      // Decodificar base64 a ArrayBuffer
      const audioData = Uint8Array.from(atob(audioBase64), c => c.charCodeAt(0))
      const audioBuffer = await audioContextRef.current.decodeAudioData(audioData.buffer)

      // Detener audio anterior si existe
      if (currentAudioRef.current) {
        currentAudioRef.current.stop()
      }

      // Reproducir audio
      const source = audioContextRef.current.createBufferSource()
      source.buffer = audioBuffer
      source.connect(audioContextRef.current.destination)
      source.onended = () => {
        setIsSpeaking(false)
        currentAudioRef.current = null
      }
      
      currentAudioRef.current = source
      source.start(0)

    } catch (error) {
      console.error('‚ùå Error reproduciendo audio:', error)
      setIsSpeaking(false)
      toast.error('Error reproduciendo el audio')
    }
  }

  const stopSpeaking = () => {
    if (currentAudioRef.current) {
      currentAudioRef.current.stop()
      currentAudioRef.current = null
      setIsSpeaking(false)
    }
  }

  return (
    <div className="flex flex-col h-full">
      {/* Indicador de cuota de voz */}
      {quotaStatus && quotaStatus.isPremium && (
        <motion.div 
          initial={{ opacity: 0, y: -10 }}
          animate={{ opacity: 1, y: 0 }}
          className="bg-gradient-to-r from-purple-500/10 to-pink-500/10 p-3 border-b border-purple-500/20 flex-shrink-0"
        >
          <div className="flex items-center justify-between mb-2">
            <div className="flex items-center gap-2">
              <Sparkles className="w-4 h-4 text-purple-500" />
              <span className="text-xs font-medium">
                Voz M√°gica Realista
              </span>
            </div>
            <span className="text-xs text-muted-foreground">
              {quotaStatus.minutesRemaining.toFixed(1)} min
            </span>
          </div>
          <Progress 
            value={quotaStatus.percentageUsed} 
            className="h-1.5"
          />
          {useMagicalLanguage && (
            <p className="text-xs text-yellow-600 dark:text-yellow-500 mt-2 flex items-center gap-1">
              <Moon className="w-3 h-3" />
              Ahora hablo en mi idioma m√°gico üåô
            </p>
          )}
        </motion.div>
      )}

      {/* Mensaje de magia agotada */}
      <AnimatePresence>
        {showMagicMessage && (
          <motion.div
            initial={{ opacity: 0, scale: 0.9 }}
            animate={{ opacity: 1, scale: 1 }}
            exit={{ opacity: 0, scale: 0.9 }}
            className="p-3 flex-shrink-0"
          >
            <Alert className="border-yellow-500/50 bg-yellow-500/10">
              <Moon className="w-4 h-4 text-yellow-500" />
              <AlertDescription className="text-xs">
                Mi magia se ha agotado... ahora solo podr√© hablar en mi idioma secreto hasta la pr√≥xima luna üåô‚ú®
              </AlertDescription>
            </Alert>
          </motion.div>
        )}
      </AnimatePresence>

      {/* Alerta de permisos */}
      {micPermissionStatus === 'denied' && (
        <Alert className="border-red-500/50 bg-red-500/10 m-3 flex-shrink-0">
          <AlertCircle className="w-4 h-4 text-red-500" />
          <AlertDescription className="text-xs">
            <strong>Micr√≥fono bloqueado.</strong> Ve a la configuraci√≥n de tu navegador y permite el acceso al micr√≥fono para esta p√°gina.
          </AlertDescription>
        </Alert>
      )}

      {micPermissionStatus === 'granted' && (
        <Alert className="border-green-500/50 bg-green-500/10 m-3 flex-shrink-0">
          <CheckCircle className="w-4 h-4 text-green-500" />
          <AlertDescription className="text-xs">
            ‚úÖ Micr√≥fono listo. Haz clic en "Hablar" para comenzar.
          </AlertDescription>
        </Alert>
      )}

      {/* √Årea de mensajes */}
      <div className="flex-1 overflow-y-auto p-4 space-y-3">
        {messages.length === 0 && (
          <div className="text-center text-gray-400 py-8">
            <Mic className="w-12 h-12 mx-auto mb-3 opacity-20" />
            <p className="text-sm">Haz clic en "Hablar" para comenzar...</p>
            <p className="text-xs mt-1">Tu {companion.name} te est√° escuchando</p>
          </div>
        )}

        {messages.map((msg, idx) => (
          <motion.div
            key={idx}
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-[80%] rounded-2xl px-4 py-2 ${
                msg.role === 'user'
                  ? 'bg-gradient-to-r from-purple-500 to-pink-500 text-white'
                  : 'bg-gray-100 text-gray-800'
              }`}
            >
              <p className="text-sm whitespace-pre-wrap">{msg.content}</p>
            </div>
          </motion.div>
        ))}

        {isProcessing && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            className="flex justify-start"
          >
            <div className="bg-gray-100 rounded-2xl px-4 py-2">
              <div className="flex items-center gap-2">
                <div className="w-2 h-2 bg-purple-500 rounded-full animate-bounce" />
                <div className="w-2 h-2 bg-purple-500 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }} />
                <div className="w-2 h-2 bg-purple-500 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }} />
              </div>
            </div>
          </motion.div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* Controles de voz */}
      <div className="p-4 bg-gray-50 border-t flex-shrink-0">
        {/* Transcripci√≥n en tiempo real */}
        {(isListening || transcript) && (
          <motion.div
            initial={{ opacity: 0, height: 0 }}
            animate={{ opacity: 1, height: 'auto' }}
            exit={{ opacity: 0, height: 0 }}
            className="mb-3 p-2 bg-white rounded-lg border"
          >
            <p className="text-xs text-gray-500 mb-1">Escuchando...</p>
            <p className="text-sm text-gray-800">
              {transcript || '...'}
            </p>
          </motion.div>
        )}

        <div className="flex items-center gap-2">
          <Button
            size="lg"
            variant={isListening ? "destructive" : "default"}
            onClick={toggleListening}
            disabled={isProcessing || micPermissionStatus === 'checking'}
            className="flex-1"
          >
            {micPermissionStatus === 'checking' ? (
              <>
                <Sparkles className="w-5 h-5 mr-2 animate-spin" />
                Verificando...
              </>
            ) : isListening ? (
              <>
                <MicOff className="w-5 h-5 mr-2" />
                Detener
              </>
            ) : (
              <>
                <Mic className="w-5 h-5 mr-2" />
                Hablar
              </>
            )}
          </Button>

          {isSpeaking && (
            <Button
              size="lg"
              variant="outline"
              onClick={stopSpeaking}
            >
              <VolumeX className="w-5 h-5" />
            </Button>
          )}
        </div>

        {/* Indicador de estado */}
        <div className="mt-2 text-center">
          {isSpeaking && (
            <motion.p
              initial={{ opacity: 0 }}
              animate={{ opacity: 1 }}
              className="text-xs text-purple-600 flex items-center justify-center gap-1"
            >
              <Volume2 className="w-3 h-3 animate-pulse" />
              {companion.name} est√° hablando...
            </motion.p>
          )}
          {isProcessing && !isSpeaking && (
            <p className="text-xs text-gray-500">Pensando...</p>
          )}
        </div>
      </div>
    </div>
  )
}
