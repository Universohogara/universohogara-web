

/**
 * Chat Emocional Simplificado
 * Con voces m√°gicas autom√°ticas y auras emocionales sutiles
 * ACTUALIZADO: Sistema mejorado con control de reproducci√≥n
 * 
 * CAMBIOS CLAVE:
 * - ‚úÖ El audio solo se reproduce cuando el mensaje est√° COMPLETO
 * - ‚úÖ Se detiene cualquier audio previo antes de reproducir uno nuevo
 * - ‚úÖ Mejor sincronizaci√≥n entre texto escrito y voz hablada
 */

'use client'

import { useState, useRef, useEffect } from 'react'
import { motion, AnimatePresence } from 'framer-motion'
import { Mic, MicOff, MessageCircle, Send, Volume2, Loader2, Play } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Textarea } from '@/components/ui/textarea'
import { ScrollArea } from '@/components/ui/scroll-area'
import { toast } from 'sonner'
import { detectEmotion, type DetectedEmotion } from '@/lib/emotion-detector'
import { cleanTextForSpeech } from '@/lib/text-cleaner'
import { getVoiceConfig } from '@/lib/voice-config'
import { usesPiperTTS, playPiperAudio } from '@/lib/piper-tts-service'
import { usesPuterTTS, playPuterAudio, stopCurrentAudio } from '@/lib/puter-tts-service'
import { getCompanionColors } from '@/lib/companion-colors'
import Image from 'next/image'
import EmotionParticles from './emotion-particles'

interface Message {
  id: string
  role: 'user' | 'assistant'
  content: string
  emotion?: DetectedEmotion
  timestamp: Date
}

interface SimpleEmotionalChatProps {
  companion: {
    id: string
    type: string
    name: string
    personality: string
  }
  onEmotionChange?: (emotion: DetectedEmotion) => void
}

export function SimpleEmotionalChat({ companion, onEmotionChange }: SimpleEmotionalChatProps) {
  // Estados
  const [messages, setMessages] = useState<Message[]>([])
  const [inputText, setInputText] = useState('')
  const [isLoading, setIsLoading] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isListening, setIsListening] = useState(false)
  const [mode, setMode] = useState<'text' | 'voice'>('voice') // MODO VOZ POR DEFECTO
  const [currentEmotion, setCurrentEmotion] = useState<DetectedEmotion>('calm')
  const [micSupported, setMicSupported] = useState(false)
  const [voicesLoaded, setVoicesLoaded] = useState(false)

  // Referencias
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const recognitionRef = useRef<any>(null)
  const audioRef = useRef<HTMLAudioElement | null>(null)

  // üé® Obtener colores personalizados del companion
  const colors = getCompanionColors(companion.type)

  // Scroll autom√°tico
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [messages])

  // Cargar voces del navegador
  useEffect(() => {
    if ('speechSynthesis' in window) {
      console.log('üé§ Inicializando sistema de voces...')
      
      // Cargar voces
      const loadVoices = () => {
        const voices = window.speechSynthesis.getVoices()
        if (voices.length > 0) {
          setVoicesLoaded(true)
          console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
          console.log('‚úÖ VOCES CARGADAS EXITOSAMENTE')
          console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
          console.log(`üìã Total de voces: ${voices.length}`)
          
          // Log de voces en espa√±ol
          const spanishVoices = voices.filter(v => 
            v.lang.includes('es') || v.lang.includes('ES')
          )
          console.log(`üá™üá∏ Voces en espa√±ol disponibles: ${spanishVoices.length}`)
          
          if (spanishVoices.length > 0) {
            console.log('Lista de voces en espa√±ol:')
            spanishVoices.forEach((v, i) => {
              console.log(`  ${i + 1}. ${v.name} (${v.lang})`)
            })
          } else {
            console.warn('‚ö†Ô∏è No se encontraron voces en espa√±ol')
          }
          console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
        }
      }

      // Cargar inmediatamente
      loadVoices()

      // Y tambi√©n cuando se dispare el evento (algunos navegadores lo necesitan)
      window.speechSynthesis.onvoiceschanged = loadVoices
      
      // Forzar carga despu√©s de un momento (para navegadores que tardan)
      setTimeout(() => {
        if (!voicesLoaded) {
          console.log('‚è∞ Intentando cargar voces de nuevo...')
          loadVoices()
        }
      }, 1000)
    } else {
      console.error('‚ùå speechSynthesis NO est√° disponible en este navegador')
    }
  }, [voicesLoaded])

  // Inicializar reconocimiento de voz
  useEffect(() => {
    if (typeof window !== 'undefined' && 'webkitSpeechRecognition' in window) {
      const SpeechRecognition = (window as any).webkitSpeechRecognition
      recognitionRef.current = new SpeechRecognition()
      recognitionRef.current.lang = 'es-ES'
      recognitionRef.current.continuous = false
      recognitionRef.current.interimResults = false
      recognitionRef.current.maxAlternatives = 1

      recognitionRef.current.onstart = () => {
        console.log('‚úÖ Micr√≥fono iniciado correctamente')
        setIsListening(true)
      }

      recognitionRef.current.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript
        console.log('üìù Transcripci√≥n:', transcript)
        setInputText(transcript)
        setIsListening(false)
        // Auto-enviar despu√©s de transcribir
        setTimeout(() => handleSendMessage(transcript), 300)
      }

      recognitionRef.current.onerror = (event: any) => {
        console.error('‚ùå Error de reconocimiento:', event.error)
        setIsListening(false)
        
        // Mensajes espec√≠ficos para cada error
        if (event.error === 'not-allowed' || event.error === 'permission-denied') {
          toast.error('üé§ Necesito acceso al micr√≥fono. Por favor permite el acceso en tu navegador.')
        } else if (event.error === 'no-speech') {
          toast('üé§ No escuch√© nada. Intenta de nuevo.', { duration: 2000 })
        } else if (event.error === 'audio-capture') {
          toast.error('‚ùå No se pudo acceder al micr√≥fono. Verifica que est√© conectado.')
        } else if (event.error === 'network') {
          toast.error('‚ùå Error de red. Verifica tu conexi√≥n.')
        } else if (event.error !== 'aborted') {
          // Solo mostrar si no fue abortado intencionalmente
          toast.error('Error al escuchar. Intenta otra vez.')
        }
      }

      recognitionRef.current.onend = () => {
        console.log('üé§ Reconocimiento finalizado')
        setIsListening(false)
      }

      setMicSupported(true)
      
      // Solicitar permisos del micr√≥fono de forma anticipada
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ audio: true })
          .then(() => {
            console.log('‚úÖ Permisos del micr√≥fono otorgados')
          })
          .catch((err) => {
            console.warn('‚ö†Ô∏è No se pudieron obtener permisos del micr√≥fono:', err)
          })
      }
    } else {
      console.warn('‚ö†Ô∏è Reconocimiento de voz no soportado')
      setMode('text') // Fallback a modo texto
    }
  }, [])

  // Limpiar recursos al desmontar
  useEffect(() => {
    return () => {
      // Detener s√≠ntesis de voz
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel()
      }
      
      // Detener cualquier audio de Puter.js
      stopCurrentAudio()
      
      // Detener reconocimiento de voz
      if (recognitionRef.current && isListening) {
        recognitionRef.current.stop()
      }
      
      // Limpiar audio (legacy, ya no se usa)
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current = null
      }
    }
  }, [isListening])

  /**
   * Iniciar/detener escucha por voz
   */
  const toggleListening = async () => {
    if (!recognitionRef.current) {
      toast.error('Tu navegador no soporta reconocimiento de voz')
      setMode('text')
      return
    }

    if (isListening) {
      try {
        recognitionRef.current.stop()
        setIsListening(false)
      } catch (error) {
        console.error('Error al detener reconocimiento:', error)
        setIsListening(false)
      }
    } else {
      try {
        // Verificar permisos del micr√≥fono primero
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          try {
            await navigator.mediaDevices.getUserMedia({ audio: true })
            console.log('‚úÖ Permisos del micr√≥fono confirmados')
          } catch (permError) {
            console.error('‚ùå Permisos denegados:', permError)
            toast.error('üé§ Necesito acceso al micr√≥fono. Permite el acceso en tu navegador.')
            return
          }
        }

        // Intentar iniciar reconocimiento
        recognitionRef.current.start()
        // El estado se actualiza en el evento onstart
        toast.success('üé§ Escuchando... habla ahora', { duration: 2000 })
      } catch (error: any) {
        console.error('Error al iniciar reconocimiento:', error)
        
        // Manejo espec√≠fico de errores
        if (error.message && error.message.includes('already')) {
          // Ya est√° escuchando - reiniciar
          try {
            recognitionRef.current.stop()
            setTimeout(() => {
              recognitionRef.current.start()
            }, 100)
          } catch (e) {
            console.error('Error al reiniciar:', e)
            setIsListening(false)
            toast.error('Error al activar el micr√≥fono. Recarga la p√°gina.')
          }
        } else {
          setIsListening(false)
          toast.error('No se pudo activar el micr√≥fono. Intenta otra vez.')
        }
      }
    }
  }

  /**
   * Reproducir respuesta con VOZ M√ÅGICA
   * - FEMENINAS CON Puter.js: Ada, Luna, Aurora, Coral
   * - MASCULINAS: Web Speech API (voces del navegador)
   * 
   * ‚ö†Ô∏è IMPORTANTE: Solo se llama cuando el mensaje est√° COMPLETO
   */
  const playVoiceResponse = async (text: string, emotion: DetectedEmotion) => {
    try {
      // Limpiar texto antes de sintetizar (quitar emojis)
      const cleanText = cleanTextForSpeech(text)
      
      if (!cleanText || cleanText.length < 2) {
        console.log('‚ö†Ô∏è Texto muy corto para sintetizar')
        return
      }

      console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
      console.log('üé§ INICIANDO VOZ M√ÅGICA')
      console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
      
      // OBTENER CONFIGURACI√ìN del companion
      const companionKey = companion.type.toLowerCase()
      const voiceConfig = getVoiceConfig(companionKey)
      
      console.log('Companion:', voiceConfig.realName, '(', companion.type, ')')
      console.log('G√©nero:', voiceConfig.gender)
      console.log('‚öôÔ∏è CONFIGURACI√ìN DE VOZ:')
      console.log('  - usePuter:', voiceConfig.usePuter)
      console.log('  - usePiper:', voiceConfig.usePiper)
      console.log('  - gender:', voiceConfig.gender)
      console.log('Texto:', cleanText.substring(0, 100) + '...')
      
      // ‚ö†Ô∏è DETENER CUALQUIER AUDIO PREVIO
      console.log('‚è∏Ô∏è Deteniendo cualquier audio previo...')
      stopCurrentAudio()
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel()
      }
      
      // Peque√±a pausa para asegurar que se detuvo
      await new Promise(resolve => setTimeout(resolve, 100))
      
      // ===================================================
      // ‚ú® PRIORIDAD 1: Puter.js TTS (voces femeninas m√°gicas)
      // ===================================================
      if (voiceConfig.usePuter === true) {
        console.log('‚ú®‚ú®‚ú® USANDO PUTER.JS TTS - VOZ M√ÅGICA AWS POLLY ‚ú®‚ú®‚ú®')
        console.log('  Personaje:', voiceConfig.realName)
        console.log('  Verificando si Puter.js est√° disponible...')
        
        // Verificar que Puter.js est√© cargado
        if (typeof window !== 'undefined' && (window as any).puter) {
          console.log('  ‚úÖ Puter.js detectado y disponible')
        } else {
          console.log('  ‚ùå Puter.js NO est√° cargado a√∫n, esperando...')
        }
        
        setIsSpeaking(true)
        
        try {
          await playPuterAudio(cleanText, companionKey, emotion)
          console.log('‚úÖ Reproducci√≥n Puter.js TTS completada con √©xito')
        } catch (error) {
          console.error('‚ùå ERROR con Puter.js TTS:', error)
          console.log('‚ö†Ô∏è Usando fallback Web Speech por error')
          // Si falla Puter.js, usar Web Speech como fallback
          await playWebSpeech(cleanText, voiceConfig, companionKey)
        } finally {
          setIsSpeaking(false)
        }
        
        console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
        return
      }
      
      // ===================================================
      // PRIORIDAD 2: Piper TTS (DESHABILITADO para femeninas)
      // ===================================================
      if (voiceConfig.usePiper === true && voiceConfig.gender === 'female') {
        console.log('üë© Usando Piper TTS (voz femenina natural)')
        setIsSpeaking(true)
        
        try {
          await playPiperAudio(cleanText, companionKey, emotion)
          console.log('‚úÖ Reproducci√≥n Piper TTS completada')
        } catch (error) {
          console.error('‚ùå Error con Piper TTS, usando fallback Web Speech:', error)
          // Si falla Piper, usar Web Speech como fallback
          await playWebSpeech(cleanText, voiceConfig, companionKey)
        } finally {
          setIsSpeaking(false)
        }
        
        console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
        return
      }
      
      // ===================================================
      // VOCES MASCULINAS: Usar Web Speech API
      // ===================================================
      console.log('üë® Usando Web Speech API (voz masculina)')
      await playWebSpeech(cleanText, voiceConfig, companionKey)
      console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')

    } catch (error) {
      console.error('‚ùå Error cr√≠tico al reproducir voz:', error)
      setIsSpeaking(false)
    }
  }

  /**
   * Reproducir con Web Speech API (voces del navegador)
   */
  const playWebSpeech = async (text: string, voiceConfig: any, companionKey: string) => {
    // Verificar soporte
    if (!('speechSynthesis' in window)) {
      console.warn('‚ö†Ô∏è S√≠ntesis de voz no soportada en este navegador')
      return
    }
    
    // Detener cualquier reproducci√≥n previa
    window.speechSynthesis.cancel()
    await new Promise(resolve => setTimeout(resolve, 150))

    // Crear utterance
    const utterance = new SpeechSynthesisUtterance(text)
    utterance.lang = 'es-ES'
    utterance.pitch = voiceConfig.pitch
    utterance.rate = voiceConfig.rate  
    utterance.volume = voiceConfig.volume

    console.log('üéõÔ∏è Configuraci√≥n aplicada:')
    console.log('  - Pitch:', utterance.pitch)
    console.log('  - Rate:', utterance.rate)
    console.log('  - Volume:', utterance.volume)

    // BUSCAR VOZ EN ESPA√ëOL CON FILTRO DE G√âNERO
    const voices = window.speechSynthesis.getVoices()
    console.log(`üìã Total voces disponibles: ${voices.length}`)
    
    if (voices.length > 0) {
      const spanishVoices = voices.filter(v => 
        v.lang.includes('es') || v.lang.includes('ES')
      )
      
      console.log(`üá™üá∏ Voces en espa√±ol: ${spanishVoices.length}`)
      
      // Filtrar por g√©nero
      const genderPreference = voiceConfig.gender
      console.log(`üë§ Buscando voz ${genderPreference}`)
      
      let filteredVoices = spanishVoices
      
      if (genderPreference === 'male') {
        filteredVoices = spanishVoices.filter(v => {
          const name = v.name.toLowerCase()
          return (
            name.includes('male') ||
            name.includes('man') ||
            name.includes('hombre') ||
            name.includes('jorge') ||
            name.includes('diego') ||
            name.includes('juan')
          )
        })
        console.log(`üë® Voces masculinas encontradas: ${filteredVoices.length}`)
      }
      
      let selectedVoice: SpeechSynthesisVoice | undefined
      
      if (filteredVoices.length > 0) {
        selectedVoice = filteredVoices.find(v => v.name.toLowerCase().includes('google'))
        if (!selectedVoice) {
          selectedVoice = filteredVoices[0]
        }
      }
      
      if (!selectedVoice && spanishVoices.length > 0) {
        console.log(`‚ö†Ô∏è No hay voces del g√©nero ${genderPreference}, usando fallback`)
        selectedVoice = spanishVoices.find(v => v.name.toLowerCase().includes('google'))
        if (!selectedVoice) {
          selectedVoice = spanishVoices[0]
        }
      }
      
      if (selectedVoice) {
        utterance.voice = selectedVoice
        console.log(`‚úÖ Voz seleccionada: ${selectedVoice.name}`)
        console.log(`   G√©nero: ${genderPreference}`)
        console.log(`   Pitch final: ${utterance.pitch.toFixed(2)}`)
      }
    }

    // Eventos
    utterance.onstart = () => {
      setIsSpeaking(true)
      console.log('‚ñ∂Ô∏è REPRODUCCI√ìN INICIADA')
    }

    utterance.onend = () => {
      setIsSpeaking(false)
      console.log(`‚úÖ REPRODUCCI√ìN COMPLETADA`)
    }

    utterance.onerror = (error) => {
      console.error('‚ùå ERROR en s√≠ntesis de voz:', error)
      setIsSpeaking(false)
    }

    // REPRODUCIR
    console.log('üéµ Llamando a speechSynthesis.speak()...')
    window.speechSynthesis.speak(utterance)
  }

  /**
   * Enviar mensaje
   * ‚ö†Ô∏è CAMBIO IMPORTANTE: La voz solo se reproduce cuando el mensaje est√° COMPLETO
   */
  const handleSendMessage = async (messageText?: string) => {
    const textToSend = messageText || inputText
    
    if (!textToSend.trim() || isLoading) return

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: textToSend,
      timestamp: new Date()
    }

    setMessages(prev => [...prev, userMessage])
    setInputText('')
    setIsLoading(true)

    try {
      // Enviar a la API de chat emocional
      const response = await fetch('/api/chat-emocional', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          message: textToSend,
          chatHistory: messages.map(m => ({
            role: m.role,
            content: m.content
          })),
          companionType: companion.type,
          companionName: companion.name,
          companionPersonality: companion.personality
        })
      })

      if (!response.ok) {
        throw new Error('Error al enviar mensaje')
      }

      // ‚ö†Ô∏è CAMBIO CLAVE: Esperar a que el streaming est√© COMPLETO
      // Leer respuesta streaming
      const reader = response.body?.getReader()
      const decoder = new TextDecoder()
      let assistantMessage = ''
      let detectedEmotion: DetectedEmotion = 'calm'

      console.log('üì• Leyendo respuesta en streaming...')

      while (true) {
        const { done, value } = await reader!.read()
        if (done) {
          console.log('‚úÖ Streaming completado')
          break
        }

        const chunk = decoder.decode(value)
        const lines = chunk.split('\n')

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6).trim()
            if (data === '[DONE]') continue

            try {
              const parsed = JSON.parse(data)
              const content = parsed.choices?.[0]?.delta?.content || ''
              assistantMessage += content
            } catch (e) {
              // Skip invalid JSON
            }
          }
        }
      }

      // ‚úÖ AQU√ç EL MENSAJE EST√Å COMPLETO
      console.log('üìù Mensaje completo recibido:', assistantMessage.substring(0, 50) + '...')

      // Detectar emoci√≥n del mensaje completo
      detectedEmotion = detectEmotion(assistantMessage)
      setCurrentEmotion(detectedEmotion)
      
      // Notificar al padre sobre el cambio de emoci√≥n
      if (onEmotionChange) {
        onEmotionChange(detectedEmotion)
      }

      // Agregar mensaje del asistente
      const newAssistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: assistantMessage,
        emotion: detectedEmotion,
        timestamp: new Date()
      }

      setMessages(prev => [...prev, newAssistantMessage])

      // ‚úÖ REPRODUCIR VOZ SOLO CUANDO EL MENSAJE EST√Å COMPLETO
      if (mode === 'voice') {
        console.log('üîä Iniciando reproducci√≥n de voz para mensaje completo...')
        await playVoiceResponse(assistantMessage, detectedEmotion)
      }

    } catch (error) {
      console.error('Error al enviar mensaje:', error)
      toast.error('Hubo un error al procesar tu mensaje')
    } finally {
      setIsLoading(false)
    }
  }

  // Mapeo de im√°genes seg√∫n el tipo de companion
  const companionImages: Record<string, string> = {
    'ken': '/images/companions/ken.png',
    'hada': '/images/companions/companion-hada-fairy.png',
    'lumi': '/images/companions/companion-lumi-light.png',
    'draguito': '/images/companions/companion-draguito-dragon.png',
    'elfo': '/images/companions/companion-elfo-elf.png',
    'fabel': '/images/companions/companion-sprig-plant.png',
    'willow': '/images/companions/companion-willow-tree.png',
    'nimbo': '/images/companions/companion-nimbo-cloud.png',
    'unicornito': '/images/companions/companion-unicornito-unicorn.png',
    'human': '/images/companions/companion-human-warm.png'
  }

  const imagePath = companionImages[companion.type.toLowerCase()] || '/images/companions/companion-hada-fairy.png'

  return (
    <div 
      className="relative flex flex-col h-full bg-gradient-to-b to-white dark:to-gray-800"
      style={{
        background: `linear-gradient(to bottom, ${colors.primary}08, white)`,
      }}
    >
      {/* Header con informaci√≥n */}
      <div className="p-4 border-b bg-white/80 dark:bg-gray-800/80 backdrop-blur-sm flex-shrink-0">
        <div className="flex items-center justify-between">
          <div>
            <h3 className="text-lg font-semibold">{companion.name}</h3>
            <p className="text-sm text-gray-600 dark:text-gray-400 flex items-center gap-2">
              {isSpeaking && <Volume2 className="w-4 h-4 animate-pulse" />}
              {isSpeaking ? 'Hablando...' : 
               isListening ? 'üé§ Escuchando...' : 
               'Listo para conversar'}
            </p>
          </div>
          
          {/* Toggle Modo: Texto / Voz */}
          <div className="flex gap-2">
            <Button
              variant={mode === 'text' ? 'default' : 'outline'}
              size="sm"
              onClick={() => setMode('text')}
            >
              <MessageCircle className="w-4 h-4 mr-2" />
              Texto
            </Button>
            {micSupported && (
              <Button
                variant={mode === 'voice' ? 'default' : 'outline'}
                size="sm"
                onClick={() => setMode('voice')}
              >
                <Volume2 className="w-4 h-4 mr-2" />
                Voz
              </Button>
            )}
          </div>
        </div>
      </div>

      {/* √Årea de mensajes */}
      <ScrollArea className="flex-1 p-4">
        <div className="space-y-4 max-w-3xl mx-auto pb-24">
          {messages.length === 0 && (
            <motion.div 
              className="text-center py-12 text-gray-500"
              initial={{ opacity: 0 }}
              animate={{ opacity: 1 }}
            >
              <p className="mb-2 text-lg">Hola, soy {companion.name}</p>
              <p className="text-sm">Estoy aqu√≠ para escucharte y acompa√±arte con mi voz m√°gica</p>
            </motion.div>
          )}

          <AnimatePresence>
            {messages.map((message) => (
              <motion.div
                key={message.id}
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: -20 }}
                className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
              >
                <div
                  className={`max-w-[80%] rounded-2xl px-4 py-3 ${
                    message.role === 'user'
                      ? 'text-white'
                      : `bg-gradient-to-br ${colors.gradient} shadow-md border ${colors.border}`
                  }`}
                  style={message.role === 'user' ? {
                    background: `linear-gradient(135deg, ${colors.primary}, ${colors.secondary})`,
                    boxShadow: `0 4px 12px ${colors.glow}`
                  } : {}}
                >
                  <p className={`text-sm whitespace-pre-wrap ${message.role === 'assistant' ? colors.text : ''}`}>
                    {message.content}
                  </p>
                  {message.role === 'assistant' && mode === 'text' && (
                    <button
                      onClick={() => playVoiceResponse(message.content, message.emotion || 'calm')}
                      className={`mt-2 flex items-center gap-1 text-xs ${colors.text} opacity-70 hover:opacity-100`}
                      disabled={isSpeaking}
                      style={{ color: colors.primary }}
                    >
                      <Play className="w-3 h-3" />
                      {isSpeaking ? 'Reproduciendo...' : 'Escuchar'}
                    </button>
                  )}
                </div>
              </motion.div>
            ))}
          </AnimatePresence>

          {isLoading && (
            <motion.div
              initial={{ opacity: 0 }}
              animate={{ opacity: 1 }}
              className="flex justify-start"
            >
              <div className="bg-white dark:bg-gray-800 shadow-md border border-gray-200 dark:border-gray-700 rounded-2xl px-4 py-3">
                <Loader2 className="w-4 h-4 animate-spin" />
              </div>
            </motion.div>
          )}

          <div ref={messagesEndRef} />
        </div>
      </ScrollArea>

      {/* Input area */}
      <div className="p-4 border-t bg-white/80 dark:bg-gray-800/80 backdrop-blur-sm flex-shrink-0">
        <div className="max-w-3xl mx-auto">
          {mode === 'text' ? (
            // Modo texto
            <div className="flex gap-2">
              <Textarea
                value={inputText}
                onChange={(e) => setInputText(e.target.value)}
                onKeyDown={(e) => {
                  if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault()
                    handleSendMessage()
                  }
                }}
                placeholder="Escribe tu mensaje..."
                className="resize-none"
                rows={2}
                disabled={isLoading}
              />
              <Button
                onClick={() => handleSendMessage()}
                disabled={!inputText.trim() || isLoading}
                size="lg"
              >
                <Send className="w-5 h-5" />
              </Button>
            </div>
          ) : (
            // Modo voz con micr√≥fono mejorado
            <div className="flex flex-col items-center gap-4">
              {/* Estado y permisos del micr√≥fono */}
              {!micSupported && (
                <div className="w-full p-3 bg-amber-50 border border-amber-200 rounded-lg text-center">
                  <p className="text-sm text-amber-800">
                    ‚ö†Ô∏è Tu navegador no soporta reconocimiento de voz. Usa el modo texto.
                  </p>
                </div>
              )}

              <motion.div
                className="relative w-full"
                animate={isListening ? {
                  boxShadow: [
                    `0 0 0 0 ${colors.glow.replace('0.5', '0')}`,
                    `0 0 0 15px ${colors.glow}`,
                    `0 0 0 0 ${colors.glow.replace('0.5', '0')}`
                  ]
                } : {}}
                transition={{
                  duration: 1.5,
                  repeat: isListening ? Infinity : 0,
                  ease: 'easeInOut'
                }}
              >
                <Button
                  onClick={toggleListening}
                  disabled={isLoading || isSpeaking || !micSupported}
                  size="lg"
                  variant={isListening ? 'default' : 'outline'}
                  className={`w-full h-20 text-lg font-semibold transition-all text-white`}
                  style={{
                    background: isListening 
                      ? `linear-gradient(135deg, ${colors.primary}, ${colors.secondary})`
                      : isSpeaking
                      ? '#10b981'
                      : 'white',
                    borderColor: colors.primary,
                    color: isListening || isSpeaking ? 'white' : colors.primary
                  }}
                  onMouseEnter={(e) => {
                    if (!isListening && !isSpeaking && !isLoading) {
                      e.currentTarget.style.background = `${colors.primary}10`
                    }
                  }}
                  onMouseLeave={(e) => {
                    if (!isListening && !isSpeaking && !isLoading) {
                      e.currentTarget.style.background = 'white'
                    }
                  }}
                >
                  {isListening ? (
                    <>
                      <motion.div
                        animate={{ scale: [1, 1.2, 1] }}
                        transition={{ duration: 0.5, repeat: Infinity }}
                      >
                        <MicOff className="w-8 h-8 mr-3" />
                      </motion.div>
                      üé§ Escuchando... Habla ahora
                    </>
                  ) : isSpeaking ? (
                    <>
                      <motion.div
                        animate={{ scale: [1, 1.1, 1] }}
                        transition={{ duration: 0.8, repeat: Infinity }}
                      >
                        <Volume2 className="w-8 h-8 mr-3" />
                      </motion.div>
                      üó£Ô∏è {companion.name} est√° hablando...
                    </>
                  ) : isLoading ? (
                    <>
                      <Loader2 className="w-8 h-8 mr-3 animate-spin" />
                      Procesando...
                    </>
                  ) : (
                    <>
                      <Mic className="w-8 h-8 mr-3" />
                      üé§ Toca para hablar con {companion.name}
                    </>
                  )}
                </Button>
              </motion.div>

              {/* Feedback de transcripci√≥n con color personalizado */}
              {inputText && !isLoading && (
                <motion.div
                  initial={{ opacity: 0, y: 10 }}
                  animate={{ opacity: 1, y: 0 }}
                  className="w-full p-3 rounded-lg"
                  style={{
                    background: `${colors.primary}10`,
                    borderColor: colors.primary,
                    borderWidth: '1px'
                  }}
                >
                  <p className="text-sm text-center" style={{ color: colors.primary }}>
                    üìù &quot;{inputText}&quot;
                  </p>
                </motion.div>
              )}

              {/* Indicador de estado del sistema */}
              <div className="w-full flex items-center justify-center gap-2 text-xs text-gray-500">
                <span className={`w-2 h-2 rounded-full ${micSupported ? 'bg-green-500' : 'bg-red-500'}`}></span>
                <span>{micSupported ? '‚úÖ Micr√≥fono disponible' : '‚ùå Micr√≥fono no disponible'}</span>
                <span className="mx-2">‚Ä¢</span>
                <span className={`w-2 h-2 rounded-full ${voicesLoaded ? 'bg-green-500' : 'bg-amber-500'}`}></span>
                <span>{voicesLoaded ? '‚úÖ Voces cargadas' : '‚è≥ Cargando voces...'}</span>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  )
}
